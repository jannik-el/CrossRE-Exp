{"related-to": {"precision": 0.037037037037037035, "recall": 0.013888888888888888, "f1-score": 0.0202020202020202, "support": 72}, "artifact": {"precision": 0.8228571428571428, "recall": 0.96, "f1-score": 0.8861538461538461, "support": 300}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 1}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 8}, "general-affiliation": {"precision": 0.8404907975460123, "recall": 0.8353658536585366, "f1-score": 0.837920489296636, "support": 328}, "named": {"precision": 0.550561797752809, "recall": 0.5212765957446809, "f1-score": 0.5355191256830601, "support": 94}, "opposite": {"precision": 0.18181818181818182, "recall": 0.14285714285714285, "f1-score": 0.16, "support": 14}, "origin": {"precision": 0.23076923076923078, "recall": 0.06382978723404255, "f1-score": 0.1, "support": 47}, "part-of": {"precision": 0.3333333333333333, "recall": 0.125, "f1-score": 0.18181818181818182, "support": 96}, "physical": {"precision": 0.7314285714285714, "recall": 0.735632183908046, "f1-score": 0.7335243553008597, "support": 174}, "role": {"precision": 0.5440251572327044, "recall": 0.6837944664031621, "f1-score": 0.6059544658493871, "support": 253}, "social": {"precision": 0.46511627906976744, "recall": 0.425531914893617, "f1-score": 0.4444444444444445, "support": 47}, "temporal": {"precision": 0.31666666666666665, "recall": 0.6551724137931034, "f1-score": 0.42696629213483145, "support": 29}, "topic": {"precision": 0.09375, "recall": 0.07142857142857142, "f1-score": 0.08108108108108107, "support": 42}, "type-of": {"precision": 1.0, "recall": 0.5, "f1-score": 0.6666666666666666, "support": 18}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 2}, "win-defeat": {"precision": 0.7326732673267327, "recall": 0.7628865979381443, "f1-score": 0.7474747474747475, "support": 97}, "micro avg": {"precision": 0.6635220125786163, "recall": 0.6504315659679408, "f1-score": 0.6569115815691159, "support": 1622}, "macro avg": {"precision": 0.40473690957871705, "recall": 0.38215673039693737, "f1-score": 0.3781015127121036, "support": 1622}, "weighted avg": {"precision": 0.6234936806954533, "recall": 0.6504315659679408, "f1-score": 0.628232458700523, "support": 1622}, "samples avg": {"precision": 0.6635220125786163, "recall": 0.6578616352201258, "f1-score": 0.6597484276729559, "support": 1622}}