{"related-to": {"precision": 0.2339622641509434, "recall": 0.1497584541062802, "f1-score": 0.1826215022091311, "support": 414}, "artifact": {"precision": 0.5903743315508021, "recall": 0.8692913385826772, "f1-score": 0.7031847133757961, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.7317073170731707, "recall": 0.774818401937046, "f1-score": 0.7526460211681695, "support": 1239}, "named": {"precision": 0.5623800383877159, "recall": 0.525089605734767, "f1-score": 0.5430954587581094, "support": 558}, "opposite": {"precision": 0.07575757575757576, "recall": 0.0390625, "f1-score": 0.05154639175257732, "support": 128}, "origin": {"precision": 0.2711864406779661, "recall": 0.10526315789473684, "f1-score": 0.15165876777251183, "support": 304}, "part-of": {"precision": 0.23330442324371206, "recall": 0.37309292649098474, "f1-score": 0.2870864461045891, "support": 721}, "physical": {"precision": 0.7001055966209081, "recall": 0.911340206185567, "f1-score": 0.7918781725888324, "support": 1455}, "role": {"precision": 0.5798588838999359, "recall": 0.4506480558325025, "f1-score": 0.5071528751753156, "support": 2006}, "social": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 105}, "temporal": {"precision": 0.6963562753036437, "recall": 0.8431372549019608, "f1-score": 0.762749445676275, "support": 408}, "topic": {"precision": 0.3333333333333333, "recall": 0.0058823529411764705, "f1-score": 0.011560693641618498, "support": 170}, "type-of": {"precision": 0.9130434782608695, "recall": 0.125, "f1-score": 0.21989528795811517, "support": 336}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 200}, "win-defeat": {"precision": 0.61, "recall": 0.5772870662460567, "f1-score": 0.5931928687196111, "support": 317}, "micro avg": {"precision": 0.5737194277803415, "recall": 0.5426669576604103, "f1-score": 0.5577613279497532, "support": 9164}, "macro avg": {"precision": 0.38419823283885746, "recall": 0.3382159600502209, "f1-score": 0.32695697911180305, "support": 9164}, "weighted avg": {"precision": 0.5429151944415037, "recall": 0.5426669576604103, "f1-score": 0.5196442894939605, "support": 9164}, "samples avg": {"precision": 0.5737194277803415, "recall": 0.5485309952315027, "f1-score": 0.5568950930626058, "support": 9164}}