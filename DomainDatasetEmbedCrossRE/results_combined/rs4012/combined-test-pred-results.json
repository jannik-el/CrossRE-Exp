{"related-to": {"precision": 0.33203125, "recall": 0.20531400966183574, "f1-score": 0.25373134328358204, "support": 414}, "artifact": {"precision": 0.7793923381770145, "recall": 0.9291338582677166, "f1-score": 0.8477011494252872, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.6818181818181818, "recall": 0.18292682926829268, "f1-score": 0.28846153846153844, "support": 82}, "general-affiliation": {"precision": 0.7375504710632571, "recall": 0.8845843422114609, "f1-score": 0.8044036697247707, "support": 1239}, "named": {"precision": 0.7875, "recall": 0.6774193548387096, "f1-score": 0.7283236994219653, "support": 558}, "opposite": {"precision": 0.18421052631578946, "recall": 0.0546875, "f1-score": 0.08433734939759037, "support": 128}, "origin": {"precision": 0.5869565217391305, "recall": 0.35526315789473684, "f1-score": 0.4426229508196721, "support": 304}, "part-of": {"precision": 0.32662835249042144, "recall": 0.47295423023578365, "f1-score": 0.3864022662889518, "support": 721}, "physical": {"precision": 0.8168831168831169, "recall": 0.8646048109965636, "f1-score": 0.8400667779632722, "support": 1455}, "role": {"precision": 0.6528129751647238, "recall": 0.6420737786640079, "f1-score": 0.6473988439306357, "support": 2006}, "social": {"precision": 0.7534246575342466, "recall": 0.5238095238095238, "f1-score": 0.6179775280898877, "support": 105}, "temporal": {"precision": 0.7938144329896907, "recall": 0.5661764705882353, "f1-score": 0.6609442060085836, "support": 408}, "topic": {"precision": 0.4, "recall": 0.03529411764705882, "f1-score": 0.06486486486486487, "support": 170}, "type-of": {"precision": 0.757396449704142, "recall": 0.38095238095238093, "f1-score": 0.5069306930693069, "support": 336}, "usage": {"precision": 0.532608695652174, "recall": 0.245, "f1-score": 0.3356164383561644, "support": 200}, "win-defeat": {"precision": 0.8104838709677419, "recall": 0.6340694006309149, "f1-score": 0.7115044247787611, "support": 317}, "micro avg": {"precision": 0.6732810336871251, "recall": 0.6368398079441292, "f1-score": 0.6545536114849708, "support": 9164}, "macro avg": {"precision": 0.584324225911743, "recall": 0.4502508097451307, "f1-score": 0.48360516140499027, "support": 9164}, "weighted avg": {"precision": 0.661945759842388, "recall": 0.6368398079441292, "f1-score": 0.6354819145109047, "support": 9164}, "samples avg": {"precision": 0.6732810336871251, "recall": 0.6472465774496231, "f1-score": 0.6558990924473158, "support": 9164}}