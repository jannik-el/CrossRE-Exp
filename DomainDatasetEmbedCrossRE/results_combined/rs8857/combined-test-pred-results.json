{"related-to": {"precision": 0.2623376623376623, "recall": 0.24396135265700483, "f1-score": 0.2528160200250313, "support": 414}, "artifact": {"precision": 0.7266387726638772, "recall": 0.8204724409448819, "f1-score": 0.7707100591715976, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.6666666666666666, "recall": 0.024390243902439025, "f1-score": 0.047058823529411764, "support": 82}, "general-affiliation": {"precision": 0.7079136690647482, "recall": 0.7941888619854721, "f1-score": 0.7485736021300875, "support": 1239}, "named": {"precision": 0.6053097345132743, "recall": 0.6129032258064516, "f1-score": 0.6090828138913624, "support": 558}, "opposite": {"precision": 0.2403846153846154, "recall": 0.1953125, "f1-score": 0.21551724137931033, "support": 128}, "origin": {"precision": 0.5, "recall": 0.22039473684210525, "f1-score": 0.3059360730593607, "support": 304}, "part-of": {"precision": 0.3128491620111732, "recall": 0.3106796116504854, "f1-score": 0.31176061238691716, "support": 721}, "physical": {"precision": 0.6054806437581557, "recall": 0.9567010309278351, "f1-score": 0.7416089504528502, "support": 1455}, "role": {"precision": 0.6411103767349636, "recall": 0.4835493519441675, "f1-score": 0.5512929809605001, "support": 2006}, "social": {"precision": 0.4594594594594595, "recall": 0.1619047619047619, "f1-score": 0.23943661971830987, "support": 105}, "temporal": {"precision": 0.7849462365591398, "recall": 0.7156862745098039, "f1-score": 0.7487179487179487, "support": 408}, "topic": {"precision": 0.25, "recall": 0.0058823529411764705, "f1-score": 0.01149425287356322, "support": 170}, "type-of": {"precision": 0.8901098901098901, "recall": 0.24107142857142858, "f1-score": 0.3793911007025761, "support": 336}, "usage": {"precision": 0.18421052631578946, "recall": 0.035, "f1-score": 0.05882352941176471, "support": 200}, "win-defeat": {"precision": 0.7133333333333334, "recall": 0.6750788643533123, "f1-score": 0.693679092382496, "support": 317}, "micro avg": {"precision": 0.6045223811721273, "recall": 0.5718027062418158, "f1-score": 0.5877074921489457, "support": 9164}, "macro avg": {"precision": 0.5029853381713381, "recall": 0.38218688464360745, "f1-score": 0.3932882188701816, "support": 9164}, "weighted avg": {"precision": 0.5879506961031766, "recall": 0.5718027062418158, "f1-score": 0.5551385359097603, "support": 9164}, "samples avg": {"precision": 0.6045223811721273, "recall": 0.5793916320566066, "f1-score": 0.5877365020766036, "support": 9164}}