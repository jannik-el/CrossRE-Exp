{"related-to": {"precision": 0.2507462686567164, "recall": 0.2028985507246377, "f1-score": 0.22429906542056074, "support": 414}, "artifact": {"precision": 0.6042128603104213, "recall": 0.8582677165354331, "f1-score": 0.709173715029278, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 1.0, "recall": 0.012195121951219513, "f1-score": 0.024096385542168676, "support": 82}, "general-affiliation": {"precision": 0.6966824644549763, "recall": 0.8305084745762712, "f1-score": 0.7577319587628866, "support": 1239}, "named": {"precision": 0.6056910569105691, "recall": 0.5340501792114696, "f1-score": 0.5676190476190476, "support": 558}, "opposite": {"precision": 0.25, "recall": 0.0859375, "f1-score": 0.12790697674418605, "support": 128}, "origin": {"precision": 0.1111111111111111, "recall": 0.05263157894736842, "f1-score": 0.07142857142857142, "support": 304}, "part-of": {"precision": 0.2752420470262794, "recall": 0.27600554785020803, "f1-score": 0.2756232686980609, "support": 721}, "physical": {"precision": 0.6225196123673281, "recall": 0.9271477663230241, "f1-score": 0.7448923246824958, "support": 1455}, "role": {"precision": 0.572063492063492, "recall": 0.4491525423728814, "f1-score": 0.5032113934655125, "support": 2006}, "social": {"precision": 0.1, "recall": 0.009523809523809525, "f1-score": 0.01739130434782609, "support": 105}, "temporal": {"precision": 0.7593052109181141, "recall": 0.75, "f1-score": 0.7546239210850803, "support": 408}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 170}, "type-of": {"precision": 0.8461538461538461, "recall": 0.09821428571428571, "f1-score": 0.176, "support": 336}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 200}, "win-defeat": {"precision": 0.5889212827988338, "recall": 0.637223974763407, "f1-score": 0.6121212121212122, "support": 317}, "micro avg": {"precision": 0.5739501615136133, "recall": 0.5428852029681361, "f1-score": 0.5579856437864513, "support": 9164}, "macro avg": {"precision": 0.42839113251598165, "recall": 0.3366915910878832, "f1-score": 0.32741877323216984, "support": 9164}, "weighted avg": {"precision": 0.5324633636516671, "recall": 0.5428852029681361, "f1-score": 0.5121873161715581, "support": 9164}, "samples avg": {"precision": 0.5739501615136133, "recall": 0.5495692970312259, "f1-score": 0.557664205506845, "support": 9164}}