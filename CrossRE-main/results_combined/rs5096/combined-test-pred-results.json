{"related-to": {"precision": 0.23809523809523808, "recall": 0.22946859903381642, "f1-score": 0.23370233702337023, "support": 414}, "artifact": {"precision": 0.533213644524237, "recall": 0.9354330708661417, "f1-score": 0.679245283018868, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 1.0, "recall": 0.04878048780487805, "f1-score": 0.09302325581395349, "support": 82}, "general-affiliation": {"precision": 0.7610156833457804, "recall": 0.8224374495560937, "f1-score": 0.7905352986811482, "support": 1239}, "named": {"precision": 0.5974264705882353, "recall": 0.5824372759856631, "f1-score": 0.5898366606170599, "support": 558}, "opposite": {"precision": 0.19047619047619047, "recall": 0.03125, "f1-score": 0.053691275167785234, "support": 128}, "origin": {"precision": 0.3563218390804598, "recall": 0.20394736842105263, "f1-score": 0.25941422594142255, "support": 304}, "part-of": {"precision": 0.24495677233429394, "recall": 0.3536754507628294, "f1-score": 0.28944381384790013, "support": 721}, "physical": {"precision": 0.6781725888324873, "recall": 0.9182130584192439, "f1-score": 0.7801459854014599, "support": 1455}, "role": {"precision": 0.6669421487603305, "recall": 0.40229312063808575, "f1-score": 0.501865671641791, "support": 2006}, "social": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 105}, "temporal": {"precision": 0.7229166666666667, "recall": 0.8504901960784313, "f1-score": 0.7815315315315317, "support": 408}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 170}, "type-of": {"precision": 0.9850746268656716, "recall": 0.19642857142857142, "f1-score": 0.32754342431761785, "support": 336}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 200}, "win-defeat": {"precision": 0.6644736842105263, "recall": 0.637223974763407, "f1-score": 0.6505636070853462, "support": 317}, "micro avg": {"precision": 0.5902168897092755, "recall": 0.558271497162811, "f1-score": 0.5737999102736653, "support": 9164}, "macro avg": {"precision": 0.4493579737517716, "recall": 0.3654163896328362, "f1-score": 0.35473778647583853, "support": 9164}, "weighted avg": {"precision": 0.5746335027388159, "recall": 0.558271497162811, "f1-score": 0.5364175014794701, "support": 9164}, "samples avg": {"precision": 0.5902168897092755, "recall": 0.5651438240270726, "f1-score": 0.5734694662359637, "support": 9164}}