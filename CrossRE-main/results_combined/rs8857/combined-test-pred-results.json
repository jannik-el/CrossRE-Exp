{"related-to": {"precision": 0.2865853658536585, "recall": 0.22705314009661837, "f1-score": 0.2533692722371968, "support": 414}, "artifact": {"precision": 0.7235142118863049, "recall": 0.8818897637795275, "f1-score": 0.794889992902768, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.6, "recall": 0.036585365853658534, "f1-score": 0.06896551724137931, "support": 82}, "general-affiliation": {"precision": 0.7043771043771043, "recall": 0.8442292171105731, "f1-score": 0.7679882525697503, "support": 1239}, "named": {"precision": 0.592823712948518, "recall": 0.6810035842293907, "f1-score": 0.6338615512927439, "support": 558}, "opposite": {"precision": 0.32857142857142857, "recall": 0.359375, "f1-score": 0.34328358208955223, "support": 128}, "origin": {"precision": 0.3917525773195876, "recall": 0.25, "f1-score": 0.30522088353413657, "support": 304}, "part-of": {"precision": 0.3121319199057715, "recall": 0.36754507628294036, "f1-score": 0.3375796178343949, "support": 721}, "physical": {"precision": 0.6826586706646677, "recall": 0.9388316151202749, "f1-score": 0.7905092592592593, "support": 1455}, "role": {"precision": 0.7084006462035541, "recall": 0.4371884346959123, "f1-score": 0.5406905055487053, "support": 2006}, "social": {"precision": 0.43478260869565216, "recall": 0.2857142857142857, "f1-score": 0.3448275862068965, "support": 105}, "temporal": {"precision": 0.7426160337552743, "recall": 0.8627450980392157, "f1-score": 0.7981859410430838, "support": 408}, "topic": {"precision": 0.5, "recall": 0.011764705882352941, "f1-score": 0.02298850574712644, "support": 170}, "type-of": {"precision": 0.9270833333333334, "recall": 0.2648809523809524, "f1-score": 0.41203703703703703, "support": 336}, "usage": {"precision": 0.7931034482758621, "recall": 0.115, "f1-score": 0.20087336244541487, "support": 200}, "win-defeat": {"precision": 0.7067448680351907, "recall": 0.7602523659305994, "f1-score": 0.7325227963525837, "support": 317}, "micro avg": {"precision": 0.6287494231656668, "recall": 0.5947184635530336, "f1-score": 0.6112606550022431, "support": 9164}, "macro avg": {"precision": 0.5550085841074063, "recall": 0.43082697677154713, "f1-score": 0.43222315666717814, "support": 9164}, "weighted avg": {"precision": 0.6284496029444595, "recall": 0.5947184635530336, "f1-score": 0.5796682142005125, "support": 9164}, "samples avg": {"precision": 0.6287494231656668, "recall": 0.6030418397169666, "f1-score": 0.6115789878480233, "support": 9164}}