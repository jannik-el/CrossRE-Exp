{"related-to": {"precision": 0.2746478873239437, "recall": 0.2826086956521739, "f1-score": 0.2785714285714286, "support": 414}, "artifact": {"precision": 0.6580493537015276, "recall": 0.8818897637795275, "f1-score": 0.7537012113055181, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 1.0, "recall": 0.024390243902439025, "f1-score": 0.047619047619047616, "support": 82}, "general-affiliation": {"precision": 0.7364074328974536, "recall": 0.8635996771589992, "f1-score": 0.7949479940564635, "support": 1239}, "named": {"precision": 0.5240875912408759, "recall": 0.6433691756272402, "f1-score": 0.577634754625905, "support": 558}, "opposite": {"precision": 0.2894736842105263, "recall": 0.171875, "f1-score": 0.2156862745098039, "support": 128}, "origin": {"precision": 0.36134453781512604, "recall": 0.14144736842105263, "f1-score": 0.20330969267139481, "support": 304}, "part-of": {"precision": 0.2871508379888268, "recall": 0.3564493758668516, "f1-score": 0.318069306930693, "support": 721}, "physical": {"precision": 0.7476744186046511, "recall": 0.8838487972508591, "f1-score": 0.8100787401574803, "support": 1455}, "role": {"precision": 0.654320987654321, "recall": 0.5019940179461615, "f1-score": 0.5681241184767278, "support": 2006}, "social": {"precision": 1.0, "recall": 0.01904761904761905, "f1-score": 0.03738317757009346, "support": 105}, "temporal": {"precision": 0.7286324786324786, "recall": 0.8357843137254902, "f1-score": 0.7785388127853882, "support": 408}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 170}, "type-of": {"precision": 0.9397590361445783, "recall": 0.23214285714285715, "f1-score": 0.3723150357995227, "support": 336}, "usage": {"precision": 0.7222222222222222, "recall": 0.065, "f1-score": 0.11926605504587157, "support": 200}, "win-defeat": {"precision": 0.693939393939394, "recall": 0.722397476340694, "f1-score": 0.7078825347758888, "support": 317}, "micro avg": {"precision": 0.6213659437009691, "recall": 0.5877346137058054, "f1-score": 0.604082548227905, "support": 9164}, "macro avg": {"precision": 0.5657476389632897, "recall": 0.3897555518742332, "f1-score": 0.38724283440595453, "support": 9164}, "weighted avg": {"precision": 0.6171159838000679, "recall": 0.5877346137058054, "f1-score": 0.571483715042826, "support": 9164}, "samples avg": {"precision": 0.6213659437009691, "recall": 0.5964851561298261, "f1-score": 0.6047531149053992, "support": 9164}}